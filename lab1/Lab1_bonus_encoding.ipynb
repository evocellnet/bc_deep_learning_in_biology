{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ad0467-fc31-4586-9d84-fea0948fb7a1",
   "metadata": {},
   "source": [
    "# Lab 1: Introduction to Neural Networks\n",
    "In this tutorial we introduce some of the concepts for working with neural networks using [Pytorch](https://pytorch.org/tutorials/recipes/recipes_index.html). The entire notebook can be executed as-is, given the lack of time for this first lab session. We encourage you to explore the code yourselves to get comfortable with the concepts of deel learning in the context of biology. A few questions at the end challenge you to play around with the code and try things for yourselves.\n",
    "\n",
    "In this session, you will create a simple neural network that classifies any given DNA sequence as protein coding or not. As a starting point, we use as examples the coding DNA sequences from humans (homo sapiens (HS)). As negatives, we use random sequences of DNA where each nucleotide is drawn from a uniform distribution over the possible nucleotides. We then train a neural network on de [codon frequencies](https://en.wikipedia.org/wiki/DNA_and_RNA_codon_tables) of these sequences. In addition to human DNA sequences, we also take a look at coding sequences from mice ([mus musculus (MM)](https://en.wikipedia.org/wiki/House_mouse)) and yeast ([saccharomyces cerevisiae (SC)](https://en.wikipedia.org/wiki/Saccharomyces_cerevisiae)). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d75f7f4-c7b1-46a8-8637-5cba8634b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# import basic functionality\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# libraries for plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import _pickle as pickle\n",
    "\n",
    "import Bio\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f5ede-7ed4-4cfc-bfdd-a9fddddbabbd",
   "metadata": {},
   "source": [
    "# Step 1: Pre-processing the data\n",
    "Here we download and pre-process the dataset. We only consider DNA sequences that are protein coding, contain a integer number of codons, and have a start and stop codon. Finally, we remove duplicates and randomly mix the sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b2d30-85ab-4aa6-837c-d2d6693584ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# download and unpack DNA coding sequences for human, mouse and yeast\n",
    "############################\n",
    "\n",
    "!mkdir -p ~/all_seqs\n",
    "%cd ~/\n",
    "\n",
    "!wget -P ~/all_seqs/ https://ftp.ensembl.org/pub/current_fasta/homo_sapiens/cds/Homo_sapiens.GRCh38.cds.all.fa.gz\n",
    "!gzip -df \"all_seqs/Homo_sapiens.GRCh38.cds.all.fa.gz\"\n",
    "\n",
    "!wget -P ~/all_seqs/ https://ftp.ensembl.org/pub/current_fasta/saccharomyces_cerevisiae/cds/Saccharomyces_cerevisiae.R64-1-1.cds.all.fa.gz\n",
    "!gzip -df \"all_seqs/Saccharomyces_cerevisiae.R64-1-1.cds.all.fa.gz\"\n",
    "\n",
    "!wget -P ~/all_seqs/ https://ftp.ensembl.org/pub/current_fasta/mus_musculus/cds/Mus_musculus.GRCm39.cds.all.fa.gz\n",
    "!gzip -df \"all_seqs/Mus_musculus.GRCm39.cds.all.fa.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b21b02-c373-4f98-895e-8424ae1fbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################\n",
    "### some unnecessarily complex code to process the FASTA files for coding sequences\n",
    "############################\n",
    "\n",
    "# function that loads and processes a FASTA file containing coding sequences\n",
    "def load_species_cds(file_name, max_nr_samples):\n",
    "    seqs = []\n",
    "    for record in SeqIO.parse(file_name, \"fasta\"):\n",
    "        # ensure that sequences are protein coding\n",
    "        if 'gene_biotype:protein_coding' in record.description:\n",
    "            if 'transcript_biotype:protein_coding' in record.description:\n",
    "                if ' cds ' in record.description:\n",
    "                    if len(record.seq) % 3 == 0:\n",
    "                        # translate sequence and check for start and stop codons\n",
    "                        code_translation = str(record.seq.translate())\n",
    "                        if (code_translation[0]=='M') & (code_translation[-1]=='*'):\n",
    "                            seqs.append(str(record.seq))\n",
    "\n",
    "    # avoid sequences with undetermined/uncertain nucleotides\n",
    "    # restrict to sequences with at least 100 aa for codon frequency estimation\n",
    "    seqs = [seqs[i] for i in range(len(seqs)) if (len(seqs[i])>=300)]#('N' not in train_cds_filtered[i]) and (len(train_cds_filtered[i])>=300)]\n",
    "    \n",
    "    # remove duplicates and randomly mix the list of sequences\n",
    "    seqs = list(set(seqs))\n",
    "    random.shuffle(seqs)\n",
    "    \n",
    "    return list(seqs)[0:max_nr_samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9f681-fc16-46e5-9565-26e8010694e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# there are many sequences, given the time constraints, we limit the number of sequences to speed up the processing\n",
    "max_nr_samples = 20000\n",
    "\n",
    "# load coding sequences for different species\n",
    "print('loading human proteins')\n",
    "seq_data_human = load_species_cds(\"all_seqs/Homo_sapiens.GRCh38.cds.all.fa\", max_nr_samples)\n",
    "\n",
    "print('loading yeast proteins')\n",
    "seq_data_yeast = load_species_cds(\"all_seqs/Saccharomyces_cerevisiae.R64-1-1.cds.all.fa\", max_nr_samples)\n",
    "\n",
    "print('loading mouse proteins')\n",
    "seq_data_mouse = load_species_cds(\"all_seqs/Mus_musculus.GRCm39.cds.all.fa\", max_nr_samples)\n",
    "\n",
    "# take a look at some sequences\n",
    "[seq_data_human[i][0:20]+'...'+seq_data_human[i][-20:] for i in range(5)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ead0a",
   "metadata": {},
   "source": [
    "# Step 2: Encoding sequences as codon frequencies\n",
    "The steps above give us a set of unique coding sequences for humans, mice and yeast. To train a neural network on de coding frequencies of these sequences, we encode the sequences by converting each sequence to an array of frequencies for each possible codon. Each codon gets assigned a index in the array. We first create a 'language' that knows all possible words (codons) for a given codon length and input sequence. This language then allows us to convert between codon (e.g., 'ATG') and indices in the array (e.g., 'ATG' -> 0) to keep track of the codon frequencies. Here, we use Tensors - the datatype used for pytorch data - to store the coding frequencies.\n",
    "\n",
    "Biologically, [DNA codons](https://en.wikipedia.org/wiki/DNA_and_RNA_codon_tables) consist of three nucleotides, encoding amino acids. However, since we are training a neural network to classify a sequence to be protein coding or not, we can choose any number of nucleotides to represent a 'codon'. For example, we can choose a \"codon length\" (codon_length) of a single nucleotide (which would result in us training the model on the [frequencies of nucleotides in DNA](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC403801/)), or a codon length of two nucleotides (no biological meaning as this does not represent a biological unit - we do not expect a model to learn any biology at all), or a codon length of 6 nucleotides (representing pairs of amino acids - would this yield a model that \"learns\" any biology?). You can play around with the codon_length yourself, but we start with a codon length of 3 nucleotides - represeting one amino acid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd4243",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class to store a language\n",
    "class Language:\n",
    "    # initialize the language, as standard we have start of sentence (SOS), end of sentence (EOS) and a padding to equalize sentence lengths (PAD)\n",
    "    def __init__(self, name, codon_len):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.n_words = 0\n",
    "        self.codon_length = codon_len\n",
    "\n",
    "\n",
    "    # function to split sentence in blocks of a given codon_length\n",
    "    def splitSentence(self, sentence):\n",
    "        return [sentence[i:i+self.codon_length] for i in range(0,len(sentence),self.codon_length) if len(sentence[i:i+self.codon_length])==self.codon_length]\n",
    "\n",
    "\n",
    "    # function to add sentence to language (add all new words in the sentence to our language)\n",
    "    def learnWords(self, sentence):\n",
    "        sentence_split = self.splitSentence(sentence)\n",
    "        for word in sentence_split:\n",
    "            if word not in self.word2index:\n",
    "                self.word2index[word] = self.n_words\n",
    "                self.index2word[self.n_words] = word\n",
    "                self.n_words += 1\n",
    "\n",
    "\n",
    "    # function to count the word frequencies in a sentence\n",
    "    def encode(self, sentence):\n",
    "        sentence_split = self.splitSentence(sentence)\n",
    "    \n",
    "        ############################\n",
    "        ### create a tensor having the number of available words as length, fill with with zeros\n",
    "        codon_freqs = torch.zeros(self.n_words)\n",
    "        ############################\n",
    "\n",
    "        # count frequencies of every word in the sentence\n",
    "        word_counts = np.unique(sentence_split, return_counts = True)\n",
    "        for i in range(len(word_counts[0])):\n",
    "            codon_freqs[self.word2index[word_counts[0][i]]] = word_counts[1][i]\n",
    "        codon_freqs /= len(sentence_split)\n",
    "\n",
    "        return codon_freqs\n",
    "\n",
    "\n",
    "    # return a sample of frequencies for all words in a language\n",
    "    # here we're matching the codon frequencies to the sequence length of the provided sequence\n",
    "    def sample_sentence(self, sentence):\n",
    "        # create a tensor having the number of available words as length, fill with with zeros\n",
    "        codon_freqs = torch.zeros(self.n_words)\n",
    "\n",
    "        # sample nr of codons in sequence based on actual data\n",
    "        # generate random sequence of codons given the current sequence length\n",
    "        nr_codons = round(len(sentence)/self.codon_length)\n",
    "        sampled_codons = list(np.random.randint(low=0, high=self.n_words, size = nr_codons, dtype=int))\n",
    "\n",
    "        # count frequencies of every codon\n",
    "        word_counts = np.unique(sampled_codons, return_counts = True)\n",
    "        for i in range(len(word_counts[0])):\n",
    "            codon_freqs[word_counts[0][i]] = word_counts[1][i]\n",
    "        codon_freqs /= nr_codons\n",
    "\n",
    "        return codon_freqs\n",
    "\n",
    "    \n",
    "    # here we define a function for encoding an entire dataset sequences\n",
    "    def encode_dataset(self, dataset):\n",
    "        # encode positives\n",
    "        encoded_positives = [{'sample':self.encode(sentence),'label':torch.Tensor([1])} for sentence in dataset]\n",
    "\n",
    "        # sample negatives following the sequence length distribution of positives\n",
    "        encoded_negatives = [{'sample':self.sample_sentence(sentence),'label':torch.Tensor([0])} for sentence in dataset]\n",
    "\n",
    "        # merge datasets and randomly mix positives and negatives\n",
    "        dataset_encoded = encoded_positives + encoded_negatives\n",
    "        random.shuffle(dataset_encoded)\n",
    "        \n",
    "        return dataset_encoded\n",
    "        \n",
    "\n",
    "    # here we define a function for encoding an entire dataset sequences\n",
    "    def encode_positives(self, dataset):\n",
    "        # encode positives\n",
    "        encoded_positives = [{'sequence':sentence,'frequencies':self.encode(sentence),'label':torch.Tensor([1])} for sentence in dataset]\n",
    "        return encoded_positives\n",
    "\n",
    "\n",
    "    # here we define a function for encoding an entire dataset sequences\n",
    "    def encode_negatives(self, dataset):\n",
    "        # sample negatives following the sequence length distribution of positives\n",
    "        encoded_negatives = [{'sequence':sentence,'frequencies':self.sample_sentence(sentence),'label':torch.Tensor([0])} for sentence in dataset]\n",
    "        return encoded_negatives\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46793ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "codon_length = 3\n",
    "\n",
    "# create a language for human DNA sequences\n",
    "dna_lang = Language(name=\"dna_human\", codon_len=codon_length)\n",
    "\n",
    "# memorize the dna language by parsing all sequences\n",
    "for cur_seq in seq_data_human:\n",
    "    dna_lang.learnWords(cur_seq)\n",
    "\n",
    "# encode data\n",
    "seq_data_human_encoded_pos = dna_lang.encode_positives(seq_data_human)\n",
    "seq_data_human_encoded_neg = dna_lang.encode_negatives(seq_data_human)\n",
    "seq_data_mouse_encoded = dna_lang.encode_positives(seq_data_mouse)\n",
    "seq_data_yeast_encoded = dna_lang.encode_positives(seq_data_yeast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3cced5-5acc-4945-aa67-71295bc2f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# store output\n",
    "with open('lab1_seq_data_human_encoded_pos.obj', \"wb\") as file_handler:\n",
    "        pickle.dump(seq_data_human_encoded_pos, file_handler)\n",
    "\n",
    "# store output\n",
    "with open('lab1_seq_data_human_encoded_neg.obj', \"wb\") as file_handler:\n",
    "        pickle.dump(seq_data_human_encoded_neg, file_handler)\n",
    "\n",
    "# store output\n",
    "with open('seq_data_mouse_encoded.obj', \"wb\") as file_handler:\n",
    "        pickle.dump(seq_data_mouse_encoded, file_handler)\n",
    "\n",
    "# store output\n",
    "with open('seq_data_yeast_encoded.obj', \"wb\") as file_handler:\n",
    "        pickle.dump(seq_data_yeast_encoded, file_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a416e-d7fe-48cc-8fe0-772e82aeb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# store output\n",
    "with open('sequence_encoding.obj', \"wb\") as file_handler:\n",
    "        pickle.dump(dna_lang, file_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9c739-0855-4723-b52d-13c7f3eb487a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79a991-3cd6-4c64-9e94-e8e1f6562c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371018f-6b2b-4404-b8ae-bc5f245740b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
