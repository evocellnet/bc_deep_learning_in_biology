{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Convolutional Neural Networks\n",
    "\n",
    "In this tutorial we will focus on Convolutional Neural Networks (CNNs).  \n",
    "We will train a model to label Brain MRI scans as either healthy or containing a tumor. \n",
    "We will use [Pytorch](https://pytorch.org/tutorials/recipes/recipes_index.html) and a [Pytorch Lightning](https://lightning.ai/docs/pytorch/stable/levels/core_skills.html) to build and train our model.  \n",
    "The notebook will give you a framework with some parts of the code left blank. Fill in the missing code to make it work. \n",
    "It will be helpful to look up Pytorch or Lightning commands on the go. The packages usually offer easy-to-use methods for everything Deep Learning related. \n",
    "\n",
    "Before we start, let's explore how CNNs work in this [CNN visualizer](https://adamharley.com/nn_vis/cnn/3d.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Imports\n",
    "\n",
    "Let's import all the Python modules that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# dealing with images\n",
    "from PIL import Image\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "import torchmetrics\n",
    "\n",
    "# Pytorch Lightning\n",
    "import lightning as L\n",
    "\n",
    "# for visualization\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if we can use GPUs\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading the data\n",
    "\n",
    "Download the dataset from: https://polybox.ethz.ch/index.php/s/cXXOTIJowCJqMbz\n",
    "\n",
    "The dataset contains images of brain MRI scans. Some of them are from healthy patients, others from patients with brain tumors.  \n",
    "We will train a model that can classify the images correctly.\n",
    "\n",
    "Unzip the downloaded folder. \n",
    "Then, add the correct path in the cell below, pointing to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### TODO #########\n",
    "# enter the path of the data directory\n",
    "data_dir = \"/path/of/datafolder\" \n",
    "\n",
    "######################\n",
    "\n",
    "# read the labels into a dataframe with pandas\n",
    "labels_df = pd.read_csv(data_dir + \"/metadata.csv\", index_col=0)\n",
    "labels_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How large is our dataset?\n",
    "Plot the class distribution below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TODO ######\n",
    "# get the percentage of normal and tumor classes in the dataset\n",
    "\n",
    "normal_percentage = \n",
    "tumor_percentage = \n",
    "\n",
    "#################\n",
    "\n",
    "print(\"Normal percentage: {}%\".format(normal_percentage))\n",
    "print(\"Tumor percentage: {}%\".format(tumor_percentage))\n",
    "\n",
    "sns.histplot(labels_df, x=\"class\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, that we have loaded the labels, we will load the images.  \n",
    "As we have seen above the images can have different file types and dimensions.   \n",
    "Next we will load the data into datasets that we can use for training. \n",
    "To simplify training the models, we will transform the pictures, to the same size and normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = data_dir + \"/Brain Tumor Data Set/Brain Tumor Data Set/\"\n",
    "# seed everything \n",
    "torch.manual_seed(42) # set random seed to have reproducibility between the tutorials\n",
    "\n",
    "# adding transforms to have same dimensions and some random rotations/flips to get more robust predictions\n",
    "transform = transforms.Compose(\n",
    "                [\n",
    "                transforms.Resize((256,256)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.RandomRotation(30),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225]) # from ImageNet\n",
    "                ]  \n",
    "            )\n",
    "\n",
    "# load the complete dataset\n",
    "full_dataset = torchvision.datasets.ImageFolder(image_dir, transform=transform) \n",
    "\n",
    "########## TODO ###############\n",
    "# create the train val and test set, e.g. using a 70%, 15%, 15% split\n",
    "# use a pytorch function to do this\n",
    "train_set, val_set, test_set = \n",
    "\n",
    "# define the dataloaders for train, validation and test (use shuffle for train only)\n",
    "batch_size_train = 256\n",
    "batch_size = 128 # for eval and test\n",
    "\n",
    "# usinf DataLoader from Pytorch\n",
    "test_loader = DataLoader(test_set, batch_size = batch_size, shuffle = False, num_workers = 16)\n",
    "val_loader = \n",
    "train_loader = \n",
    "\n",
    "###############################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of the images we have loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots n random brain MRI images from the passed dataset\n",
    "def plot_images(dataset, n=16):\n",
    "    CLA_label = {\n",
    "    0 : 'Brain Tumor',\n",
    "    1 : 'Healthy'\n",
    "    } \n",
    "    cols, rows = 4, int(np.ceil(n/4))\n",
    "    figure = plt.figure(figsize=(10, 10))\n",
    "    for i in range(1, n + 1):\n",
    "        sample_idx = torch.randint(len(dataset), size=(1,)).item()\n",
    "        # read out image and label from item\n",
    "        img, label = dataset[sample_idx]\n",
    "        figure.add_subplot(rows, cols, i)\n",
    "        plt.title(CLA_label[label])\n",
    "        plt.axis(\"off\")\n",
    "        img_np = img.numpy().transpose((1, 2, 0))\n",
    "        # Clip pixel values to [0, 1]\n",
    "        img_valid_range = np.clip(img_np, 0, 1)\n",
    "        plt.imshow(img_valid_range)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(train_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood the images are just vectors though.  \n",
    "In the dataset each item is saved together with it's label. \n",
    "The images in the dataset all have a size of 256x256 and 3 color channels (RBG). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first item from dataset, the item is just a tuple\n",
    "first_item = train_set[0]\n",
    "\n",
    "####### TODO #########\n",
    "# get image at index 0 and label at index 1 from the item\n",
    "image_tensor = \n",
    "label = \n",
    "\n",
    "# print the shape of the image tensor and the tensor \n",
    "print(image_tensor)\n",
    "print(\"Shape: \", image_tensor.shape)\n",
    "#####################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above vector/tensor encodes the picture below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing tensor as image\n",
    "img_valid_range = np.clip(image_tensor.numpy().transpose((1, 2, 0)), 0, 1)\n",
    "plt.imshow(img_valid_range)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Creating a CNN architecture\n",
    "\n",
    "Here is a recap of how convolutions work and CNNs work:\n",
    "https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function\n",
    "\n",
    "This function computes the new dimensions of our data after convolution and max pooling.  \n",
    "It will be helpful later when we build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the output shape of our data after a convolution and pooling of a certain size\n",
    "\n",
    "def get_conv2d_out_shape(tensor_shape, conv, pool=2):\n",
    "    # return the new shape of the tensor after a convolution and pooling\n",
    "    # tensor_shape: (channels, height, width)\n",
    "    # convolution arguments\n",
    "    kernel_size = conv.kernel_size\n",
    "    stride=conv.stride # 2D array\n",
    "    padding=conv.padding # 2D array\n",
    "    dilation=conv.dilation # 2D array\n",
    "    out_channels = conv.out_channels\n",
    "\n",
    "    height_out = np.floor((tensor_shape[1]+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
    "    width_out = np.floor((tensor_shape[2]+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
    "    \n",
    "    if pool:\n",
    "        # adjust dimensions to pooling\n",
    "        height_out/=pool\n",
    "        width_out/=pool\n",
    "        \n",
    "    return int(out_channels),int(height_out),int(width_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some simple tests\n",
    "t1 = torch.randn(3, 256, 256)\n",
    "t2 = torch.randn(5, 256, 256)\n",
    "conv1 = nn.Conv2d(in_channels=3, out_channels = 256, kernel_size=10)\n",
    "conv2 = nn.Conv2d(in_channels=3, out_channels = 64, kernel_size=4)\n",
    "conv3 = nn.Conv2d(in_channels=5, out_channels = 13, kernel_size=7)\n",
    "print(get_conv2d_out_shape(t1.shape, conv1, pool=2))\n",
    "print(get_conv2d_out_shape(t1.shape, conv2, pool=1))\n",
    "print(get_conv2d_out_shape(t2.shape ,conv3, pool=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can you explain the output above? How does the size change after a convolution and why?**\n",
    "\n",
    "Your answer:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model\n",
    "\n",
    "We can now build our Convolutional Neural Network. \n",
    "It will have two convolutional layers and two fully connected layers.  \n",
    "You will be able to mostly use Pytorch methods to fill in the blanks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIModel(nn.Module):\n",
    "    \n",
    "    # Network Initialisation\n",
    "    def __init__(self, params):\n",
    "        \n",
    "        super(MRIModel, self).__init__() #initialize parent pytorch module\n",
    "\n",
    "        # read parameters\n",
    "        shape_in = params[\"shape_in\"]\n",
    "        channels_out = params[\"initial_depth\"] \n",
    "        fc1_size = params[\"fc1_size\"]\n",
    "        \n",
    "        #### Convolution Layers\n",
    "\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        ##conv layer 1\n",
    "        # convolution with kernel size 8, goes from three channels to \n",
    "        # number defined by initial_depth in params\n",
    "        self.conv1 = nn.Conv2d(shape_in[0], channels_out, kernel_size=8)\n",
    "\n",
    "        ############### TODO ################\n",
    "        # get current shape after conv1, use helper function get_conv2d_out_shape, use pool=2\n",
    "        current_data_shape = \n",
    "\n",
    "        ##conv layer 2\n",
    "        # convolution with kernel size 4, double the amount of channels\n",
    "        self.conv2 = nn.Conv2d(current_data_shape[0], current_data_shape[0]*2, kernel_size=4)\n",
    "        # get current shape after conv2, use pool=2 again\n",
    "        current_data_shape = \n",
    "\n",
    "        #### Fully connected layers\n",
    "        # compute the flattened size as input for fully connected layer\n",
    "        flat_size = current_data_shape[0] * current_data_shape[1] * current_data_shape[2]\n",
    "        \n",
    "        # linear layer reduces data from flat_size to fc1_size\n",
    "        self.fc1 = \n",
    "        # last linear layer reduces data to output size 2\n",
    "        self.fc2 = nn.Linear(fc1_size, 2)\n",
    "        \n",
    "        #####################################\n",
    "        \n",
    "\n",
    "    def forward(self,X):\n",
    "        # our network's forward pass\n",
    "        \n",
    "        # Convolution & Pool Layers\n",
    "        ############# TODO ###############\n",
    "        # convolution (conv1), then relu, then max pool \n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = self.pool(X)\n",
    "        # convolution (conv2), then relu, then max pool \n",
    "        X =\n",
    "\n",
    "        X = torch.flatten(X, 1) # flatten all dimensions except batch\n",
    "\n",
    "        # fully connected layer and ReLU\n",
    "        X = \n",
    "        # second fully connected layer, no relu needed\n",
    "        X = \n",
    "\n",
    "        #####################################\n",
    "        # return log softmax to fit classification problem, no relu needed\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is defining a class. This will allow us to create objects of that class. \n",
    "\n",
    "**What does ``self.`` do in the code? What is it good for in a class?**\n",
    "\n",
    "Your answer:\n",
    "\n",
    "Let's try an example and see how the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take first batch from the train loader\n",
    "batch = next(iter(train_loader))[0]\n",
    "# create the model\n",
    "cnn_model = MRIModel(params={\"shape_in\":batch[0].shape,\"initial_depth\":4,\"fc1_size\":128})\n",
    "# forward pass\n",
    "out = cnn_model(batch)\n",
    "# print shape of the input batch\n",
    "print(\"Shape of the input batch: \", batch.shape)\n",
    "# print the output shape\n",
    "print(\"Shape of the output: \", out.shape)\n",
    "# prediction output for first image, exp to get from log back to probabilities\n",
    "print(torch.exp(out[0].detach()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain the shapes of the batch and the output shown above.**\n",
    "\n",
    "Your answer:\n",
    "\n",
    "**How do you interpret the prediction for the first image?**\n",
    "\n",
    "Your answer:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validation with Lightning\n",
    "\n",
    "Now that we have created our model architecture, we will wrap a Lightning module around it. \n",
    "This will make the training procedure much easier.  \n",
    "Instead of programming the whole training loops ourselves, we will define how one step should be handled at training, validation and testing.  \n",
    "We only need to define how to retreive data from the batch, how to pass it through our model and how/when to compute the loss. \n",
    "The rest will be all handled by Lightning.  \n",
    "Make sure to use the Lightning docs and Google, to find the right methods.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMRIModel(L.LightningModule):\n",
    "    def __init__(self, model_parameters, learning_rate=1e-2):\n",
    "        super().__init__()\n",
    "        ######## TODO ##########\n",
    "        # Instantiate our model like above\n",
    "        self.model = MRIModel(model_parameters)\n",
    "        #pass the learning rate\n",
    "        self.lr = \n",
    "        # define loss function\n",
    "        self.loss_function = nn.NLLLoss(reduction=\"mean\")\n",
    "        # define accuracy metric (torchmetrics)\n",
    "        self.accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        ########################\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        ######### TODO #############\n",
    "        \n",
    "        # read from batch\n",
    "        x, y = \n",
    "\n",
    "        # run data through model\n",
    "        predictions = \n",
    "        \n",
    "        # compute loss\n",
    "        loss = \n",
    "        # compute accuracy\n",
    "        acc = \n",
    "        ##############################\n",
    "\n",
    "        # logging the values (will appear in progress bar and on dashboard)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        ############## TODO ################\n",
    "        # define the optimizer, let's use Adam\n",
    "        optimizer = \n",
    "        ####################################\n",
    "        return optimizer\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "\n",
    "        ############### TODO #############\n",
    "        # read from batch\n",
    "        x, y = \n",
    "\n",
    "        # run data through model\n",
    "        predictions = \n",
    "        \n",
    "        # compute loss\n",
    "        loss = \n",
    "        # compute accuracy\n",
    "        acc = \n",
    "        ##############################\n",
    "\n",
    "        # logging\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)\n",
    "        return loss, acc\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        ############### TODO #############\n",
    "        # read from batch\n",
    "        x, y = \n",
    "\n",
    "        # run data through model\n",
    "        predictions = \n",
    "        \n",
    "        # compute loss\n",
    "        loss = \n",
    "        # compute accuracy\n",
    "        acc = \n",
    "        ##############################\n",
    "\n",
    "        # logging\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "        return loss \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "To visualize the training procedure, we will use Tensorboard.  \n",
    "In the code above we can see some values being logged. Tensorboard will display these values in nice graphs for us to follow our learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tensorboard session\n",
    "# new tab should open in your browser\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Training and evaluating \n",
    "\n",
    "Now that everything is ready, we can start training the model.  \n",
    "Make sure to follow its performance on Tensorboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "model_parameters={\n",
    "        \"shape_in\": (3,256,256), # size of our images\n",
    "        \"initial_depth\": 4,    \n",
    "        \"fc1_size\": 128}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "########## TODO #############\n",
    "# instantiate lightning model with the cnn_model and learning_rate=1e-3\n",
    "model = \n",
    "############################\n",
    "\n",
    "# instantiate the lightning trainer \n",
    "trainer = L.Trainer(max_epochs=20, log_every_n_steps=1)\n",
    "# train\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the learning curves in tensorboard. (You might need to click the refresh button on the website). \n",
    "Answer the following questions below. Write the answers in this cell.\n",
    "\n",
    "1. **How many steps are there in one epoch? How do you compute it?**\n",
    "\n",
    "    Your answer:\n",
    "\n",
    "2. **What is the difference between the metrics per step and per epoch?**\n",
    "\n",
    "    Your answer:\n",
    "\n",
    "3. **Which metrics/graphs can help you understand whether your model is learning something useful from the data?**\n",
    "\n",
    "    Your answer\n",
    "\n",
    "4. **How well did your model train? Would you improve something? Explain your answer.**\n",
    "\n",
    "    Your answer:\n",
    "\n",
    "5. **How could you see from the graphs if your model is overfitting?**\n",
    "\n",
    "    Your answer:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate and visualize\n",
    "\n",
    "Let us evaluate the model now. As we might still make changes, and tune parameters, we should not use the test set, yet. \n",
    "The test set is only for the final evaluation and should never be looked at before to ensure unbiased models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the validation set\n",
    "trainer.validate(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualize our predictions in a confusion matrix to get a feeling of how well the model performs in specific cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# get the predictions and plot a confusion matrix\n",
    "\n",
    "# function to retrieve the predictions of the model and return them with the true labels\n",
    "def get_predictions(val_loader, model):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for images, labels in val_loader:\n",
    "        images = images#.to(device)\n",
    "        labels = labels.numpy()\n",
    "        outputs = model.model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        \n",
    "        y_true = np.append(y_true, labels)\n",
    "        y_pred = np.append(y_pred, pred)\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "########## TODO #############\n",
    "# get predictions from the cnn_model on the val_loader\n",
    "y_true, y_pred = \n",
    "############################\n",
    "\n",
    "# print summary\n",
    "print(classification_report(y_true, y_pred), '\\n\\n')\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the information we get from the confusion matrix compare to what we can learn from the training curves?**\n",
    "\n",
    "Your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# get predictions (as probabilities)\n",
    "def get_prediction_probs(val_loader, model):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for images, labels in val_loader:\n",
    "        images = images#.to(device)\n",
    "        labels = labels.numpy()\n",
    "        outputs = model.model(images)\n",
    "        # exp() because we use log softmax as last layer\n",
    "        # get the probabilities for tomor class \n",
    "        prediction_probabilities = torch.exp(outputs)[:,1] \n",
    "        pred = prediction_probabilities.detach().cpu().numpy()\n",
    "    \n",
    "        y_true = np.append(y_true, labels)\n",
    "        y_pred = np.append(y_pred, pred)\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "y_true, y_pred_probabilities = get_prediction_probs(val_loader, model)\n",
    "\n",
    "########## TODO #############\n",
    "# compute ROC curve and ROC area for each class\n",
    "# use sklearn roc_curve and auc functions\n",
    "fpr, tpr, _ = \n",
    "roc_auc = au\n",
    "##############################\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=2, label='AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], lw=2, linestyle='--', color=\"grey\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the U.S. 21.97 of 100,000 people are diagnosed with brain tumors.  \n",
    "Assume a doctor uses our model to screen 100,000 persons from the U.S. \n",
    "\n",
    "**Based on the computed values above, how many healthy people do we expect to be wrongly diagnosed with brain cancer?**\n",
    "\n",
    "Your answer:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Improving\n",
    "\n",
    "### Finetuning training parameters\n",
    "\n",
    "The training procedure could use some improvements.  \n",
    "Adjust the number of epochs, batch size and learning rate and rerun the model.  \n",
    "Analyze how performance changes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model with a large learning rate (e.g. 1e-1)\n",
    "# make sure to name your lightning model variable in a way to not overwrite the previously trained model\n",
    "\n",
    "########## TODO #############\n",
    "# instantiate lightning model\n",
    "model_large_lr = \n",
    "# define trainer, 20 epochs\n",
    "trainer =\n",
    "# train\n",
    "\n",
    "##############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model with a small learning rate (e.g. 1e-5)\n",
    "\n",
    "########## TODO #############\n",
    "# instantiate lightning model\n",
    "model_small_lr = \n",
    "# define trainer, 20 epochs\n",
    "trainer =\n",
    "# train\n",
    "\n",
    "##############################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the learning rate influence training performance?**\n",
    "\n",
    "Your answer:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let's use the original learning rate of 1e-3 again. \n",
    "Now we will change the batch size in the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightning model\n",
    "model_small_batches = LitMRIModel(model_parameters, learning_rate=1e-3)\n",
    "\n",
    "#### TODO ####\n",
    "## create train dataloader with a small batch size\n",
    "train_loader_small = \n",
    "\n",
    "# train model\n",
    "trainer =\n",
    "# train with smaller batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightning model\n",
    "model_big_batches = LitMRIModel(model_parameters, learning_rate=1e-3)\n",
    "\n",
    "#### TODO ####\n",
    "# train with a large batch size, what's the largest batch size you can use?\n",
    "train_loader_big = \n",
    "\n",
    "# train model\n",
    "trainer = \n",
    "# train\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the batch size influence the model performance?**\n",
    "\n",
    "Your answer:\n",
    "\n",
    "Now let's train for more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightning model\n",
    "model_long_training = LitMRIModel(model_parameters, learning_rate=1e-3)\n",
    "\n",
    "# train the model for 100 epochs\n",
    "trainer = \n",
    "# train on train_loader again\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the model perform? How do more epochs influence performance and how many epochs are enough?**\n",
    "\n",
    "Your answer:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model improvements (optional)\n",
    "\n",
    "Simply finding the best training parameters improves the performance to some degree.  \n",
    "Especially in more complex problems and with larger datasets the architecture and the amount and size of the layers also matter. \n",
    "Now you can experiment with the CNN architecture. \n",
    "Use the code from a bove and create a deeper or larger model (Eg. 4 conv layers and 2 fully connected).  \n",
    "Or simply experiment around with the model parameters. Maybe use different kernel sizes. Try to see if you can further improve the preformance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# TODO ##################\n",
    "# create a more complex model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# TODO ##################\n",
    "# train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# TODO ##################\n",
    "# validate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Final testing\n",
    "\n",
    "Now that we have a well performing model, we can run the model on the test set and see how it performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### TODO #################\n",
    "# pass the best performing model here\n",
    "best_model =\n",
    "\n",
    "# test your best performing model on the test set\n",
    "trainer.test(best_model, test_loader)\n",
    "\n",
    "# print the confusion matrix and classification report\n",
    "y_true, y_pred = \n",
    "\n",
    "print(classification_report(y_true, y_pred), '\\n\\n')\n",
    "# confusion matrix\n",
    "cm = \n",
    "\n",
    "sns.heatmap(cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2 (main, Apr 14 2023, 09:06:29) [GCC 8.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fa888489dcef296c36d3d3b759d2bbafdf14549bdfa862d5619a4427d05b08f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
